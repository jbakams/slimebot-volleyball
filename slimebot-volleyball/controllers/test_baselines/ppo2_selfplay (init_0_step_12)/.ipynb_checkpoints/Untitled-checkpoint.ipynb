{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "183d4900",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55588494",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('progress.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "319887c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clipfrac</th>\n",
       "      <th>explained_variance</th>\n",
       "      <th>ep_reward_mean</th>\n",
       "      <th>value_loss</th>\n",
       "      <th>policy_entropy</th>\n",
       "      <th>approxkl</th>\n",
       "      <th>total_timesteps</th>\n",
       "      <th>fps</th>\n",
       "      <th>ep_len_mean</th>\n",
       "      <th>n_updates</th>\n",
       "      <th>policy_loss</th>\n",
       "      <th>serial_timesteps</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027771</td>\n",
       "      <td>-2.178616</td>\n",
       "      <td>-4.625000</td>\n",
       "      <td>0.093154</td>\n",
       "      <td>3.461802</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>4096</td>\n",
       "      <td>632</td>\n",
       "      <td>463.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031555</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>-4.833333</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>3.452324</td>\n",
       "      <td>0.003717</td>\n",
       "      <td>8192</td>\n",
       "      <td>627</td>\n",
       "      <td>440.944444</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>8192</td>\n",
       "      <td>6.472324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.642311</td>\n",
       "      <td>-4.888889</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>3.446449</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>12288</td>\n",
       "      <td>633</td>\n",
       "      <td>439.555556</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.003910</td>\n",
       "      <td>12288</td>\n",
       "      <td>12.997491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028503</td>\n",
       "      <td>0.762531</td>\n",
       "      <td>-4.891892</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>3.445571</td>\n",
       "      <td>0.003678</td>\n",
       "      <td>16384</td>\n",
       "      <td>641</td>\n",
       "      <td>433.216216</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.004273</td>\n",
       "      <td>16384</td>\n",
       "      <td>19.466021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028564</td>\n",
       "      <td>0.788064</td>\n",
       "      <td>-4.914894</td>\n",
       "      <td>0.008326</td>\n",
       "      <td>3.439171</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>20480</td>\n",
       "      <td>635</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>20480</td>\n",
       "      <td>25.855402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clipfrac  explained_variance  ep_reward_mean  value_loss  policy_entropy  \\\n",
       "0  0.027771           -2.178616       -4.625000    0.093154        3.461802   \n",
       "1  0.031555            0.276190       -4.833333    0.019001        3.452324   \n",
       "2  0.025208            0.642311       -4.888889    0.011847        3.446449   \n",
       "3  0.028503            0.762531       -4.891892    0.009945        3.445571   \n",
       "4  0.028564            0.788064       -4.914894    0.008326        3.439171   \n",
       "\n",
       "   approxkl  total_timesteps  fps  ep_len_mean  n_updates  policy_loss  \\\n",
       "0  0.004027             4096  632   463.125000          1    -0.005525   \n",
       "1  0.003717             8192  627   440.944444          2    -0.003882   \n",
       "2  0.003136            12288  633   439.555556          3    -0.003910   \n",
       "3  0.003678            16384  641   433.216216          4    -0.004273   \n",
       "4  0.003712            20480  635   430.000000          5    -0.004424   \n",
       "\n",
       "   serial_timesteps  time_elapsed  \n",
       "0              4096      0.000008  \n",
       "1              8192      6.472324  \n",
       "2             12288     12.997491  \n",
       "3             16384     19.466021  \n",
       "4             20480     25.855402  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5f887",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data['total_timesteps'], data[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a066a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3af9518",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_env(gym.Env):\n",
    "    \n",
    "    def __init__(self, render_mode = False, and_whatever_you_wanna):\n",
    "        \n",
    "        self.observation_space = \n",
    "        self.action_space = \n",
    "        self.t =\n",
    "        self.max_t = \n",
    "        self.policy = None # in case a predefined aggents is in the env\n",
    "        self.render_mode = render_mode\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        #observation: the next state due to the action applied\n",
    "        #reward: the reward received\n",
    "        #done: True or False that tell if the episode is over or not\n",
    "        \n",
    "        #return the next state, reward, done, infos\n",
    "        pass\n",
    "        \n",
    "    def reset(self):\n",
    "        #reset the env on its initial state\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def render(self):\n",
    "        #display the env on a pop up screen\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
